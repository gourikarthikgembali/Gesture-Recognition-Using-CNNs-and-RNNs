# Gesture Recognition Models

This project builds two deep-learning models for realâ€‘time gesture recognition using video sequences:

1. **2D CNN + RNN (MobileNet + GRU)**
2. **3D CNN**

Both models classify **5 hand gestures** from video clips of 30 frames each.

---

## âœ¨ Features
- Custom **video frame generator**
- **Transfer learning** with MobileNet (frozen base)
- **GRU-based** sequence modeling
- **3D CNN** for spatiotemporal features
- **Model checkpoints** & **ReduceLROnPlateau**
- Accuracy/Loss plots for training vs. validation

---

## ğŸ“ Dataset
- Input: folders of **30â€‘frame** sequences
- Image size: **128 Ã— 128 Ã— 3**
- Labels: `train.csv` and `val.csv`

Folder layout:
```
Project_data/
â”œâ”€â”€ train/
â”‚   â””â”€â”€ <video_folder_1>/frame_000.jpg ... frame_029.jpg
â””â”€â”€ val/
    â””â”€â”€ <video_folder_k>/frame_000.jpg ... frame_029.jpg
```

---

## ğŸ§  Models

### 1) 2D CNN + RNN
- **MobileNet** (imagenet, `include_top=False`) via `TimeDistributed`
- GRU(64) â†’ Dropout(0.2) â†’ Dense(64, relu) â†’ Dense(5, softmax)
- Lightweight & webcamâ€‘friendly

### 2) 3D CNN
- Conv3D(32) â†’ MaxPool3D â†’ Conv3D(64) â†’ MaxPool3D â†’ Dropout(0.2)
- Flatten â†’ Dense(128, relu) â†’ Dense(5, softmax)

---

## ğŸš€ Training
- Epochs: **25**
- Batch size: **32**
- Callbacks:
  - `ModelCheckpoint` (best `val_categorical_accuracy`)
  - `ReduceLROnPlateau` (monitor `val_loss`)
- Steps per epoch computed from sequence counts

---

## ğŸ“Š Evaluation
- Accuracy & loss curves for both models using Matplotlib
- Console logs show perâ€‘epoch train/val metrics

---

## ğŸ›  Requirements
- Python â‰¥ 3.8
- TensorFlow / Keras
- NumPy
- OpenCVâ€‘Python
- Matplotlib

Install:
```bash
pip install tensorflow numpy opencv-python matplotlib
```

---

## â–¶ï¸ Usage
1. Place dataset under `Project_data/train` and `Project_data/val` with 30 frames per folder.
2. Run the script to:
   - Load data via the custom generator
   - Train **2D CNN + RNN** and **3D CNN**
   - Save best checkpoints in timestamped folders
3. Use the plotting functions to visualize accuracy/loss.

---

## âš ï¸ Notes
- Ensure each folder has **exactly 30 frames**.
- Images are **resized to 128Ã—128** and **normalized to [0,1]** inside the generator.
- MobileNet base is **frozen** for faster training and to prevent overfitting; you can unfreeze for fineâ€‘tuning if needed.

---

## ğŸ“„ License
This project is for educational and research purposes.
